{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:45:33.961856Z",
     "start_time": "2020-05-06T17:45:33.958404Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import spotipy\n",
    "from spotipy import util\n",
    "from spotipy import oauth2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:49:09.996614Z",
     "start_time": "2020-05-06T17:49:09.986761Z"
    },
    "code_folding": [
     50,
     63,
     83,
     111,
     142,
     147,
     152,
     158,
     171,
     196,
     212,
     252,
     274,
     330,
     356,
     380
    ]
   },
   "outputs": [],
   "source": [
    "# A class to manage all of the storm functions and authentication\n",
    "class Storm:\n",
    "    \n",
    "    def __init__(self, scope, user_id, client_id, client_secret, inputs, output, archive, name, start_date=None):\n",
    "        \n",
    "        # Variables\n",
    "        self.scope = scope\n",
    "        self.user_id = user_id\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.token = None\n",
    "        self.token_start = None\n",
    "        self.sp = None\n",
    "        self.inputs = inputs\n",
    "        self.output = output\n",
    "        self.archive = archive\n",
    "        self.name = name\n",
    "        self.start_date = start_date\n",
    "        self.window_date = None\n",
    "        \n",
    "        # Initialization\n",
    "        self.authenticate()\n",
    "        self.gen_dates()\n",
    "        \n",
    "        # I/O Params\n",
    "        self.artist_id_csv = 'storm_artists_'+self.name+'.csv'\n",
    "        self.album_id_csv = 'storm_albums_'+self.name+'.csv'\n",
    "        self.md_name = 'storm_run_metadata_'+self.name+'.csv'\n",
    "        \n",
    "        # Dataframe init\n",
    "        self.blacklist = []\n",
    "        self.artist_ids = []\n",
    "        self.album_ids = []\n",
    "        self.albums = pd.DataFrame(columns = ['album_group', 'album_type', 'artists', 'available_markets',\n",
    "                               'external_urls', 'href', 'id', 'images', 'name', 'release_date',\n",
    "                               'release_date_precision', 'total_tracks', 'type', 'uri'])\n",
    "        self.new_ablums = pd.DataFrame()\n",
    "        self.new_tracks = pd.DataFrame(columns = ['artists', 'available_markets', 'disc_number', 'duration_ms',\n",
    "                               'explicit', 'external_urls', 'href', 'id', 'is_local', 'name',\n",
    "                               'preview_url', 'track_number', 'type', 'uri'])\n",
    "        self.storm_track_ids = []\n",
    "        \n",
    "        \n",
    "        # Interesting Metadata\n",
    "        self.mdf = pd.read_csv(self.md_name).set_index('run_date')\n",
    "        self.rd = dt.datetime.now().strftime(\"%Y/%m/%d\")\n",
    "        self.mdf.loc[self.rd, 'start_date'] = self.start_date\n",
    "        \n",
    "            \n",
    "    # Authentication Functions\n",
    "    def authenticate(self):\n",
    "        \n",
    "        print(\"Generating Token and Authenticating. . .\")\n",
    "        self.token = util.prompt_for_user_token(self.user_id,\n",
    "                                                scope=self.scope,\n",
    "                                                client_id=self.client_id,\n",
    "                                                client_secret=self.client_secret,\n",
    "                                                redirect_uri='http://localhost/')\n",
    "        self.sp = spotipy.Spotify(auth=self.token)\n",
    "        self.token_start = dt.datetime.now()\n",
    "        print(\"Authentication Complete.\")\n",
    "        print()\n",
    "    \n",
    "    def check_token(self):\n",
    "        \n",
    "        if abs((self.token_start - dt.datetime.now()).total_seconds()) < 3580:\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Awaiting Expiration and Refreshing.\")\n",
    "            time.sleep(25)\n",
    "            self.authenticate()\n",
    "\n",
    "    def gen_dates(self):\n",
    "        \n",
    "        # Start Dates\n",
    "        if self.start_date == None:\n",
    "            self.start_date = (dt.datetime.now() - dt.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "        # Playlist Cycling dates\n",
    "        self.window_date = (dt.datetime.now() - dt.timedelta(days=14)).strftime(\"%Y-%m-%d\")\n",
    "     \n",
    "    \n",
    "    # Ochestration Function\n",
    "    def Run(self):\n",
    "        \n",
    "        # Read-in existing data from past runs\n",
    "        self.read_in()\n",
    "        \n",
    "        # Augment artist list before track collection\n",
    "        self.augment_artist_list()\n",
    "        self.clean_artists()\n",
    "        self.save_artists()\n",
    "        \n",
    "        # Get Album lists\n",
    "        self.get_artist_albums()\n",
    "        self.filter_albums()\n",
    "        \n",
    "        # Tracks\n",
    "        self.get_album_tracks()\n",
    "        self.clean_tracks()\n",
    "        \n",
    "        # Playlist Writing\n",
    "        self.archive_current()\n",
    "        self.add_tracks_to_playlist(self.output, self.storm_track_ids)\n",
    "        \n",
    "        # Metadata save\n",
    "        self.save_md()\n",
    "        self.save_albums()\n",
    "        \n",
    "    \n",
    "    # I/O\n",
    "    def read_in(self):\n",
    "        \n",
    "        print(\"Reading in existing Data.\")\n",
    "        \n",
    "        if path.exists(self.artist_id_csv):\n",
    "            print(\"Storm Arists Found! Reading in now.\")\n",
    "            self.artist_ids = pd.read_csv(self.artist_id_csv)['artists'].values.tolist()\n",
    "            self.mdf.loc[self.rd, 'artists_tracked'] = len(self.artist_ids)\n",
    "            print(f\"Done! {len(self.artist_ids)} Unique Artists found.\")\n",
    "            \n",
    "        else:\n",
    "            self.mdf.loc[self.rd, 'artists_tracked'] = 0\n",
    "        print()\n",
    "            \n",
    "        if path.exists('storm_blacklist_'+self.name+'.csv'):\n",
    "            print(\"Blacklisted Arists Found! Reading in now.\")\n",
    "            self.blacklist = pd.read_csv('storm_blacklist_'+self.name+'.csv')['artists'].tolist()\n",
    "            self.mdf.loc[self.rd, 'blacklisted_artists'] = len(self.blacklist)\n",
    "            print(f\"Done! {len(self.blacklist)} Blacklisted Artists found.\")\n",
    "        print()\n",
    "            \n",
    "        if path.exists(self.album_id_csv):\n",
    "            print(\"Previously Discovered Albums Found! Reading in now.\")\n",
    "            self.album_ids = pd.read_csv(self.album_id_csv)['albums'].values.tolist()\n",
    "            self.mdf.loc[self.rd, 'albums_tracked'] = len(self.album_ids)\n",
    "            print(f\"Done! {len(self.album_ids)} Albums found.\") \n",
    "            \n",
    "        else:\n",
    "            self.mdf.loc[self.rd, 'albums_tracked'] = 0\n",
    "        print()\n",
    "    \n",
    "    def save_artists(self):\n",
    "        \n",
    "        print(\"Saving Artist Ids.\")\n",
    "        pd.DataFrame(self.artist_ids, columns=['artists']).to_csv(self.artist_id_csv, index=False)\n",
    "    \n",
    "    def save_albums(self):\n",
    "        print(\"Saving Albums from run.\")\n",
    "        self.album_ids = self.albums.id.tolist()\n",
    "        pd.DataFrame(self.album_ids, columns=['albums']).to_csv(self.album_id_csv, index=False)\n",
    "    \n",
    "    def save_md(self):\n",
    "        \n",
    "        print(\"Writing metadata from run.\")\n",
    "        self.mdf.to_csv(self.md_name)\n",
    "    \n",
    "    # Storm Aggregate Functions\n",
    "    def augment_artist_list(self):\n",
    "         \n",
    "        # Comb through playlists and get the artist ids\n",
    "        print(\"Augmenting new Artists from playlist input dictionary.\")\n",
    "        for pl in self.inputs.keys():\n",
    "            print(\"Obtaining a list of Tracks from Playlist . . .\" + pl)\n",
    "            playlist_df = self.get_playlist_tracks(self.inputs[pl])\n",
    "\n",
    "            print(\"Finding Artists . . .\")\n",
    "            self.extend_artists(playlist_df['track'])\n",
    "        \n",
    "        print(\"Done! All Input Playlists Scanned.\")\n",
    "\n",
    "    def get_playlist_tracks(self, playlist_id):\n",
    "        \n",
    "        lim = 50\n",
    "        more_tracks = True\n",
    "        offset=0\n",
    "\n",
    "        self.check_token()\n",
    "        playlist_results = self.sp.user_playlist_tracks(self.user_id, playlist_id, limit=lim, offset=offset)\n",
    "        \n",
    "        if len(playlist_results['items']) < lim:\n",
    "                more_tracks = False\n",
    "\n",
    "        while more_tracks:\n",
    "\n",
    "            self.check_token()\n",
    "            offset += lim\n",
    "            batch = self.sp.user_playlist_tracks(self.user_id, playlist_id, limit=lim, offset=offset)\n",
    "            playlist_results['items'].extend(batch['items'])\n",
    "\n",
    "            if len(batch['items']) < lim:\n",
    "                more_tracks = False\n",
    "\n",
    "        response_df = pd.DataFrame(playlist_results['items'])\n",
    "        return response_df\n",
    "    \n",
    "    def extend_artists(self, track_df):\n",
    "\n",
    "        new_artists = []\n",
    "        for track in track_df:\n",
    "            try:\n",
    "                artists = dict(track)['artists']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            for artist in artists:\n",
    "                if artist['id'] not in self.artist_ids:\n",
    "                    self.check_token()\n",
    "                    artist_info = self.sp.artist(artist['id'])\n",
    "                    if 'classical' not in artist_info['genres']:\n",
    "                        self.artist_ids.append(artist['id'])\n",
    "    \n",
    "    def clean_artists(self):\n",
    "\n",
    "        print(\"Removing Blacklist Artists.\")\n",
    "        self.filter_blacklist()\n",
    "    \n",
    "    def clean_tracks(self):\n",
    "        \n",
    "        self.storm_track_ids = np.unique(self.storm_track_ids)\n",
    "        self.new_tracks = self.new_tracks.drop_duplicates('id').reset_index(drop=True)\n",
    "        newids = []\n",
    "        \n",
    "        print(\"Checking Tracks for bad features.\")\n",
    "        print(\"Starting track amount: \"+str(len(self.new_tracks)))\n",
    "        for index in tqdm(self.new_tracks.index):\n",
    "            \n",
    "            artists = self.new_tracks.loc[index, 'artists']\n",
    "            check=True\n",
    "            \n",
    "            # Check artists\n",
    "            for artist in artists:\n",
    "                if artist['id'] in self.blacklist:\n",
    "                     check = False\n",
    "            \n",
    "            # If still a valid track, check a few features\n",
    "            if check:\n",
    "                \n",
    "                # Get track features\n",
    "                af = self.sp.audio_features(self.new_tracks.loc[index, 'id'])[0]\n",
    "                \n",
    "                try:\n",
    "                    if af['instrumentalness'] < .5:\n",
    "                        check = False\n",
    "                    elif af['speechiness'] > .32:\n",
    "                        check = False\n",
    "                    elif af['duration_ms'] < 60001:\n",
    "                        check = False\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Remove if certain features don't clear\n",
    "            if check:\n",
    "                 newids.append(self.new_tracks.loc[index, 'id'])\n",
    "        print(\"Ending Track Amount: \" + str(len(newids)))\n",
    "        self.storm_track_ids = newids\n",
    "        self.mdf.loc[self.rd, 'tracks_added'] = len(self.storm_track_ids)\n",
    "        self.mdf.loc[self.rd, 'tracks_removed'] = self.mdf.loc[self.rd, 'tracks_eligible'] - self.mdf.loc[self.rd, 'tracks_added']\n",
    "    \n",
    "    def filter_classical(self):\n",
    "\n",
    "        output_list = []\n",
    "        for artist in tqdm(self.artist_ids):\n",
    "            self.check_token()\n",
    "            artist_info = self.sp.artist(artist)\n",
    "\n",
    "            if 'classical' not in artist_info['genres']:\n",
    "                output_list.append(artist)\n",
    "\n",
    "        self.artist_ids = output_list\n",
    "        \n",
    "    def filter_blacklist(self):\n",
    "\n",
    "        output_list = []\n",
    "        for artist in tqdm(self.artist_ids):\n",
    "            if artist not in self.blacklist:\n",
    "                output_list.append(artist)\n",
    "\n",
    "        self.artist_ids = output_list\n",
    "        self.mdf.loc[self.rd, 'artists_augmented'] = len(self.artist_ids)-self.mdf.loc[self.rd, 'artists_tracked']\n",
    "    \n",
    "    def get_artist_albums(self):\n",
    "        \n",
    "        print(\"Obtaining all albums from the list of artists. (Albums)\")\n",
    "        lim = 50\n",
    "        for artist_id in tqdm(self.artist_ids):\n",
    "            \n",
    "            self.check_token()\n",
    "            response = self.sp.artist_albums(artist_id, limit=lim, album_type='album', country='US')\n",
    "            offset = 0\n",
    "            more_albums = True\n",
    "\n",
    "            while more_albums:\n",
    "                \n",
    "                self.check_token()\n",
    "                batch = self.sp.artist_albums(artist_id, limit=lim, offset=offset, album_type='album', country='US')\n",
    "                response['items'].extend(batch['items'])\n",
    "                offset += lim\n",
    "\n",
    "                if len(batch['items']) < lim:\n",
    "                        more_albums = False\n",
    "\n",
    "            response_df = pd.DataFrame(response['items'])\n",
    "            self.albums = pd.concat([self.albums, response_df], axis=0)\n",
    "           \n",
    "        print(f\"Albums being tracked: {len(self.albums)}\")\n",
    "        print(\"Obtaining all albums from the list of artists. (Singles)\")\n",
    "        for artist_id in tqdm(self.artist_ids):\n",
    "            \n",
    "            self.check_token()\n",
    "            response = self.sp.artist_albums(artist_id, limit=lim, album_type='single', country='US')\n",
    "            offset = 0\n",
    "            more_albums = True\n",
    "\n",
    "            while more_albums:\n",
    "                \n",
    "                self.check_token()\n",
    "                batch = self.sp.artist_albums(artist_id, limit=lim, offset=offset, album_type='single', country='US')\n",
    "                response['items'].extend(batch['items'])\n",
    "                offset += lim\n",
    "\n",
    "                if len(batch['items']) < lim:\n",
    "                        more_albums = False\n",
    "\n",
    "            response_df = pd.DataFrame(response['items'])\n",
    "            response_df = response_df\n",
    "            self.albums = pd.concat([self.albums, response_df], axis=0)\n",
    "            \n",
    "        print(f\"Albums being tracked: {len(self.albums)}\")\n",
    "   \n",
    "    def filter_albums(self):\n",
    "        \n",
    "        # Or Condition, either its new or hasn't been viewed\n",
    "        print(\"Filtering Album list for new content.\")\n",
    "        self.new_albums = self.albums[(~self.albums.id.isin(self.album_ids)) | (self.albums.release_date >= self.start_date)]\n",
    "        self.mdf.loc[self.rd, 'albums_augmented'] = len(self.new_albums)\n",
    "          \n",
    "    def get_album_tracks(self):\n",
    "        \n",
    "        lim = 50\n",
    "        print(\"Using Filtered albums to obtain a track list.\")\n",
    "        for album_id in tqdm(self.new_albums.id):\n",
    "            self.check_token()\n",
    "            response = self.sp.album_tracks(album_id, limit=lim)\n",
    "            offset = 0\n",
    "            more_tracks = True\n",
    "            if len(response['items']) < lim:\n",
    "                    more_tracks = False\n",
    "\n",
    "            while more_tracks:\n",
    "                \n",
    "                self.check_token()\n",
    "                batch = self.sp.album_tracks(album_id, limit=lim, offset=offset)\n",
    "                response['items'].extend(batch['items'])\n",
    "                offset += lim\n",
    "\n",
    "                if len(batch['items']) < lim:\n",
    "                    more_tracks = False\n",
    "\n",
    "            response_df = pd.DataFrame(response['items'])\n",
    "            self.new_tracks = pd.concat([self.new_tracks, response_df], axis=0)\n",
    "        self.mdf.loc[self.rd, 'tracks_eligible'] = len(self.new_tracks)\n",
    "    \n",
    "    def archive_current(self):\n",
    "        \n",
    "        # Read-in current tracks\n",
    "        print(\"Archiving Current Storm Listening.\")\n",
    "        current_listening = self.get_playlist_tracks(self.output)\n",
    "        current_archive = self.get_playlist_tracks(self.archive)\n",
    "        \n",
    "        try:\n",
    "            track_ids_cur = [dict(track)['id'] for track in current_listening.track]\n",
    "            track_ids_arc = [dict(track)['id'] for track in current_archive.track]\n",
    "            track_ids_writing = []\n",
    "\n",
    "            for track in track_ids_cur:\n",
    "                if track not in track_ids_arc:\n",
    "                    track_ids_writing.append(track)\n",
    "\n",
    "            # Write them to the archive playlist\n",
    "            if len(track_ids_writing) == 0:\n",
    "                print(\"No Unique tracks to Archive.\")\n",
    "            else:\n",
    "                self.add_tracks_to_playlist(self.archive, track_ids_writing, replace=False)\n",
    "        except:\n",
    "            print(\"No Tracks to Archive.\")\n",
    "    \n",
    "    def add_tracks_to_playlist(self, playlist_id, track_ids, replace=True):\n",
    "        \n",
    "        print(\"Preparing Tracks for Writing\")\n",
    "        lim = 50\n",
    "        if len(self.storm_track_ids) > lim:\n",
    "            split_tracks = np.array_split(track_ids, np.ceil(len(track_ids)/lim))\n",
    "\n",
    "            print(\"Writing Tracks\")\n",
    "            if replace:\n",
    "                self.check_token()\n",
    "                self.sp.user_playlist_replace_tracks(self.user_id, playlist_id, split_tracks[0])\n",
    "                for track_list in tqdm(split_tracks[1:]):\n",
    "                    self.check_token()\n",
    "                    self.sp.user_playlist_add_tracks(self.user_id, playlist_id, track_list)\n",
    "            else:\n",
    "                for track_list in tqdm(split_tracks):\n",
    "                    self.check_token()\n",
    "                    self.sp.user_playlist_add_tracks(self.user_id, playlist_id, track_list)\n",
    "        else:\n",
    "            print(\"Writing Tracks\")\n",
    "            if replace:\n",
    "                self.check_token()\n",
    "                self.sp.user_playlist_replace_tracks(self.user_id, playlist_id, self.storm_track_ids)\n",
    "            else:\n",
    "                self.check_token()\n",
    "                self.sp.user_playlist_add_tracks(self.user_id, playlist_id, self.storm_track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:56:06.578188Z",
     "start_time": "2020-05-06T17:49:10.645686Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Shared Variables and Functions\n",
    "sc = 'user-follow-read playlist-modify-private playlist-modify-public user-follow-modify'\n",
    "user = '1241528689'\n",
    "cid = '9b41900f606c4e55855524f448917d64'\n",
    "secret = '3277c16b708548369ce1f42deed974ea'\n",
    "\n",
    "# Playlist Inputs\n",
    "output_playlist = {'daily':'7fnvajjUoWBQDo8iFNMH3s',\n",
    "                   'archive':'1Q8WS7Xj51WCHZctXGDsrp'}\n",
    "\n",
    "# Inputs\n",
    "inputs = {'Much Needed':'7N3pwZE1N38wcdiuLxiPvq',\n",
    "                  'Room on the Boat':'1SZS16UcW0XOzgh6UWXA9S',\n",
    "                  'Refuge':'3K9no6AflSDYiiMzignAm7',\n",
    "                  'Safety':'0R1gw1JbcOFD0r8IzrbtYP',\n",
    "                  'Shelter from the Storm':'2yueH0i9C2daBRawYIc9P8',\n",
    "                  'Soundtracked':'37i9dQZF1DWW7gj0FcGEx6',\n",
    "                  'Soundtrack for Study':'0hZNf3tcMT4x03FyjKYJ3M',\n",
    "                  'Film Music - Movie Scores':'5GhatXsZVNYxrhqEAfZPLR',\n",
    "                  'Video Game Soundtracks':'3Iwd2RiXCzmm1AMUpRAaHO',\n",
    "                  'Video Game Music Unofficial':'3aI7ztMmDhMHhYe1KOPFLG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Token and Authenticating. . .\n",
      "Authentication Complete.\n",
      "\n",
      "Reading in existing Data.\n",
      "Storm Arists Found! Reading in now.\n",
      "Done! 1398 Unique Artists found.\n",
      "\n",
      "Blacklisted Arists Found! Reading in now.\n",
      "Done! 192 Blacklisted Artists found.\n",
      "\n",
      "Previously Discovered Albums Found! Reading in now.\n",
      "Done! 56153 Albums found.\n",
      "\n",
      "Augmenting new Artists from playlist input dictionary.\n",
      "Obtaining a list of Tracks from Playlist . . .Much Needed\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Room on the Boat\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Refuge\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Safety\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Shelter from the Storm\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Soundtracked\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Soundtrack for Study\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Film Music - Movie Scores\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Video Game Soundtracks\n",
      "Finding Artists . . .\n",
      "Obtaining a list of Tracks from Playlist . . .Video Game Music Unofficial\n",
      "Finding Artists . . .\n",
      "Done! All Input Playlists Scanned.\n",
      "Removing Blacklist Artists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06a2914343d4c5e9cf8ed7baad510ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1448), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Artist Ids.\n",
      "Obtaining all albums from the list of artists. (Albums)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6c99525695496c9e3048be8aad64b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1398), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:304: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albums being tracked: 27501\n",
      "Obtaining all albums from the list of artists. (Singles)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f2f511871143b1964e4a5d1c37f66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1398), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:327: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "Albums being tracked: 46311\n",
      "Filtering Album list for new content.\n",
      "Using Filtered albums to obtain a track list.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4513769096491db39072b51006fe0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Tracks for bad features.\n",
      "Starting track amount: 134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8f3bed848b4e669366b58de325210d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=134), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending Track Amount: 112\n",
      "Archiving Current Storm Listening.\n",
      "No Tracks to Archive.\n",
      "Preparing Tracks for Writing\n",
      "Writing Tracks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0eb0dcf45d467b94d764f17566bc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing metadata from run.\n",
      "Saving Albums from run.\n"
     ]
    }
   ],
   "source": [
    "# Authorized spotipy object\n",
    "storm = Storm(sc, user, cid, secret, inputs, \n",
    "              output_playlist['daily'], output_playlist['archive'], 'instrumental')#, start_date='2020-05-23')\n",
    "\n",
    "storm.Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plots and Processing\n",
    "df = storm.mdf\n",
    "\n",
    "df['track_added_sum'] = df.tracks_added.cumsum()\n",
    "df['track_elig_sum'] = df.tracks_eligible.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize = (15, 10));\n",
    "df.artists_tracked.plot(ax=ax[0][0]).set_title(\"Artists Tracked\");\n",
    "df.blacklisted_artists.plot(ax=ax[1][0]).set_title(\"Blacklisted Artists\");\n",
    "df.albums_augmented.plot(ax=ax[0][1]).set_title(\"Albums Augmented\");\n",
    "df.albums_tracked.plot(ax=ax[1][1]).set_title(\"Albums Tracked\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(15, 10));\n",
    "df[['tracks_added', 'tracks_eligible']].plot(ax=ax[0]).set_title('Tracks Added by Day');\n",
    "df[['track_added_sum', 'track_elig_sum']].plot(ax=ax[1]).set_title('Tracks Added Cumulatively');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
